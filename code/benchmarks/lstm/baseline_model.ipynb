{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Importing necessary packages & files"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from lstm import lstm\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"via_train_test/train.csv\")\n",
    "train_set = train_set.drop(['Unnamed: 0'], axis = 1)\n",
    "train_set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_set = pd.read_csv(\"via_train_test/test.csv\")\n",
    "test_set = test_set.drop(['Unnamed: 0'], axis = 1)\n",
    "test_set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Converting data to time series (one feature)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2D array to store all of the individual (2000) time series\n",
    "ts_data = []\n",
    "\n",
    "for id in sorted(list(set(train_set[\"id\"]))):\n",
    "    # create full time series, first all filled with observations of 0\n",
    "    full_timesteps = 48 * 7 * 24 # 48 weeks * 7 days a week * 24 hours a day\n",
    "    t_series = [0 for x in range(full_timesteps)]\n",
    "\n",
    "    # selecting from respect DFs to only get data from user\n",
    "    id_train_set = train_set.loc[train_set[\"id\"] == id]\n",
    "    id_test_set = test_set.loc[test_set[\"id\"] == id]\n",
    "\n",
    "    week_dayhour = list(zip(id_train_set[\"week\"], id_train_set[\"dayhour\"])) + \\\n",
    "                    list(zip(id_test_set[\"week\"], id_test_set[\"dayhour\"]))\n",
    "\n",
    "    # converting each pair (week, dayhour) into raw hour index from 0-8063 and\n",
    "    # adding that observation to the time series\n",
    "    for pair in week_dayhour:\n",
    "        hour_idx = ((pair[0] - 1) * 168) + pair[1]\n",
    "        # data index starts at 1, convert to index starting at 0\n",
    "        hour_idx -= 1\n",
    "\n",
    "        # adding a ride request observation at the time series\n",
    "        t_series[hour_idx] += 1\n",
    "\n",
    "    ts_data.append(t_series)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Taking a look at some of the time series signals"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "px.line(ts_data[2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating walk-forward validation train/test splits"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_train_walk(time_series, train_len, in_sample, out_sample, walk_timestep):\n",
    "    '''\n",
    "    Takes in the time series data (full 48) for one full user and\n",
    "    returns \"walks\" that represent train/validation splits\n",
    "    :param int list time_series: 1D array of full 48 week time series data for one user\n",
    "    :param train_len: Length of training period (in hours);\n",
    "    Function assumes train period is at beginning of time series\n",
    "    :param in_sample: Length of sub-time series input into LSTM for one step prediction\n",
    "    :param out_sample: Length of sub-time series output from LSTM for one step prediction\n",
    "    :param walk_timestep: Interval of walk\n",
    "    :return: X, Training set (Each item has dims of in_sample)\n",
    "    :return: y, Validation set (Each item has dims of out_sample)\n",
    "    '''\n",
    "    X, y = list(), list()\n",
    "    in_start = 0\n",
    "    for obs in range(int(train_len / walk_timestep)):\n",
    "        in_end = in_start + in_sample\n",
    "        out_end = in_end + out_sample\n",
    "\n",
    "        # checking to make sure there's sufficient data\n",
    "        if out_end <= train_len:\n",
    "            x_input = np.array(time_series[in_start: in_end])\n",
    "            x_input = x_input.reshape((len(x_input), 1))\n",
    "            X.append(x_input)\n",
    "            y.append(time_series[in_end: out_end])\n",
    "\n",
    "        # moving along the walk according to the walk_timestep\n",
    "        in_start += walk_timestep\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating heat map of probability predictions of a week's day hours from the LSTM model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_weekly_heatmaps(t_series, train_len, predictions):\n",
    "    days = [\"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\"]\n",
    "\n",
    "    predictions = predictions.reshape((7, 24))\n",
    "    test_data = t_series[train_len:]\n",
    "    test_data = np.array(test_data)\n",
    "    test_data = test_data.reshape((int(len(test_data) / 168), 7, 24))\n",
    "    week_11_data = test_data[0]\n",
    "\n",
    "    print(\"LSTM Predicted Outcomes\")\n",
    "    fig = px.imshow(predictions, y=days)\n",
    "    fig.show()\n",
    "\n",
    "    print(\"Week 11 Testing Data Heatmap\")\n",
    "    fig2 = px.imshow(week_11_data, y=days)\n",
    "    fig2.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Putting everything together and creating model for a single user"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def one_step_lstm(user_idx,\n",
    "                  train_len,\n",
    "                  in_sample,\n",
    "                  out_sample,\n",
    "                  walk_timestep,\n",
    "                  epochs,\n",
    "                  batch_size):\n",
    "    user_X, user_y = create_train_walk(ts_data[user_idx], train_len, in_sample, out_sample, walk_timestep)\n",
    "\n",
    "    user_model = lstm(in_sample, out_sample)\n",
    "    user_model.train(user_X, user_y, epochs, batch_size)\n",
    "\n",
    "    user_predictions = user_model.forecast(ts_data[user_idx][(train_len - in_sample) : train_len])\n",
    "\n",
    "    create_weekly_heatmaps(ts_data[user_idx], train_len, user_predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_len = 168 * 38\n",
    "in_sample = 168 * 3\n",
    "out_sample = 168\n",
    "walk_timestep = 168\n",
    "epochs = 8\n",
    "batch_size = 1\n",
    "\n",
    "one_step_lstm(825, train_len, in_sample, out_sample, walk_timestep, epochs, batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Conducting recursive call to get all 10 weeks\n",
    "> Using .20 as a threshold based on qualitative observations from users with routines to forecast"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Function that converts list of metrics into an average (skipping over nan)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def average(lst):\n",
    "    real_vals_lst = [x for x in lst if not np.isnan(x)]\n",
    "    return sum(real_vals_lst) / len(real_vals_lst)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def multi_step_lstm(user_idx,\n",
    "                    train_len,\n",
    "                    in_sample,\n",
    "                    out_sample,\n",
    "                    walk_timestep,\n",
    "                    epochs,\n",
    "                    batch_size):\n",
    "    user_X, user_y = create_train_walk(ts_data[user_idx], train_len, in_sample, out_sample, walk_timestep)\n",
    "\n",
    "    user_model = lstm(\"individual\", in_sample, out_sample)\n",
    "    user_model.train(user_X, user_y, epochs, batch_size)\n",
    "\n",
    "    # Storing AP/Prec respectively for within training data and forecasting out\n",
    "    in_metrics = []\n",
    "    out_metrics = []\n",
    "\n",
    "    # multi-step forecast within training data\n",
    "    in_forecast_steps = int((train_len - in_sample) / out_sample)\n",
    "    in_probs, in_preds = user_model.multi_step_forecast(ts_data[user_idx], train_len, 0, in_forecast_steps)\n",
    "\n",
    "    # multi-step forecasting out of training data\n",
    "    out_forecast_steps = int((len(ts_data[user_idx]) - train_len) / out_sample)\n",
    "    out_probs, out_preds = user_model.multi_step_forecast(ts_data[user_idx], train_len, train_len - in_sample, out_forecast_steps)\n",
    "\n",
    "    # adding AP/prec metrics for in sample\n",
    "    in_metrics.append(user_model.average_precision(ts_data[user_idx][in_sample: train_len], in_probs))\n",
    "    in_metrics.append(user_model.conditional_precision(ts_data[user_idx][in_sample: train_len], in_preds))\n",
    "\n",
    "    # adding AP/prec metrics for out sample\n",
    "    out_metrics.append(user_model.average_precision(ts_data[user_idx][train_len: ], out_probs))\n",
    "    out_metrics.append(user_model.conditional_precision(ts_data[user_idx][train_len: ], out_preds))\n",
    "\n",
    "    return in_metrics, out_metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user_idx = 825\n",
    "train_len = 168 * 38\n",
    "in_sample = 168 * 3\n",
    "out_sample = 168\n",
    "walk_timestep = 168\n",
    "epochs = 8\n",
    "batch_size = 1\n",
    "\n",
    "in_metrics, out_metrics = multi_step_lstm(user_idx, train_len, in_sample, out_sample, walk_timestep, epochs, batch_size)\n",
    "print(in_metrics)\n",
    "print(out_metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_len = 168 * 38\n",
    "in_sample = 168 * 3\n",
    "out_sample = 168\n",
    "walk_timestep = 168\n",
    "epochs = 8\n",
    "batch_size = 1\n",
    "\n",
    "# in training data metrics\n",
    "in_ap_scores = []\n",
    "in_prec_scores = []\n",
    "\n",
    "# out of training data metrics\n",
    "out_ap_scores = []\n",
    "out_prec_scores = []\n",
    "\n",
    "for user_idx in tqdm(range(len(ts_data))):\n",
    "    in_metrics, out_metrics = multi_step_lstm(user_idx, train_len, in_sample, out_sample, walk_timestep, epochs, batch_size)\n",
    "    print(in_metrics)\n",
    "    print(out_metrics)\n",
    "\n",
    "    in_ap_scores.append(in_metrics[0])\n",
    "    in_prec_scores.append(in_metrics[1])\n",
    "    out_ap_scores.append(out_metrics[0])\n",
    "    out_prec_scores.append(out_metrics[1])\n",
    "\n",
    "print(average(in_ap_scores))\n",
    "print(average(in_prec_scores))\n",
    "print(average(out_ap_scores))\n",
    "print(average(out_prec_scores))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining and executing aggregate model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def agg_multi_step_lstm(train_len,\n",
    "                        in_sample,\n",
    "                        out_sample,\n",
    "                        walk_timestep,\n",
    "                        epochs,\n",
    "                        batch_size):\n",
    "\n",
    "    # initializing training data set\n",
    "    X, y = _, _\n",
    "    for idx, ts in enumerate(ts_data):\n",
    "        # retrieving train walks for one user and concatenating it to X, y\n",
    "        user_X, user_y = create_train_walk(ts, train_len, in_sample, out_sample, walk_timestep)\n",
    "        # on first iteration, set X and y = to user_X and user_y\n",
    "        if idx == 0:\n",
    "            X = user_X\n",
    "            y = user_y\n",
    "        else:\n",
    "            # on subsequent iterations, just concatenate training data from new user with X and y\n",
    "            X = np.concatenate((X, user_X), axis=0)\n",
    "            y = np.concatenate((y, user_y), axis=0)\n",
    "\n",
    "    agg_model = lstm(\"aggregate\", in_sample, out_sample)\n",
    "    agg_model.train(X, y, epochs, batch_size, shuffle=True, verbose=1)\n",
    "\n",
    "    # Array to store all the ap/precision scores\n",
    "    twodim_in_metrics = []\n",
    "    twodim_out_metrics = []\n",
    "\n",
    "    # predicting along all the users\n",
    "    for user_ts in tqdm(ts_data):\n",
    "        # Array to store the ap/precision scores for current user (in sample and out of sample)\n",
    "        in_metrics = []\n",
    "        out_metrics = []\n",
    "\n",
    "        # multi-step forecast within training data\n",
    "        in_forecast_steps = int((train_len - in_sample) / out_sample)\n",
    "        in_probs, in_preds = agg_model.multi_step_forecast(user_ts, train_len, 0, in_forecast_steps)\n",
    "\n",
    "        # multi-step forecasting out of training data\n",
    "        out_forecast_steps = int((len(user_ts) - train_len) / out_sample)\n",
    "        out_probs, out_preds = agg_model.multi_step_forecast(user_ts, train_len, train_len - in_sample, out_forecast_steps)\n",
    "\n",
    "        # adding AP/prec metrics for in sample\n",
    "        in_metrics.append(agg_model.average_precision(user_ts[in_sample: train_len], in_probs))\n",
    "        in_metrics.append(agg_model.conditional_precision(user_ts[in_sample: train_len], in_preds))\n",
    "\n",
    "        # adding AP/prec metrics for out sample\n",
    "        out_metrics.append(agg_model.average_precision(user_ts[train_len: ], out_probs))\n",
    "        out_metrics.append(agg_model.conditional_precision(user_ts[train_len: ], out_preds))\n",
    "\n",
    "        # Adding metrics from current user_ts to the master metrics list\n",
    "        print(in_metrics)\n",
    "        print(out_metrics)\n",
    "        twodim_in_metrics.append(in_metrics)\n",
    "        twodim_out_metrics.append(out_metrics)\n",
    "\n",
    "    return twodim_in_metrics, twodim_out_metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_len = 168 * 38\n",
    "in_sample = 168 * 3\n",
    "out_sample = 168\n",
    "walk_timestep = 168\n",
    "epochs = 1\n",
    "batch_size = 16\n",
    "\n",
    "in_metrics_list, out_metrics_list = agg_multi_step_lstm(train_len, in_sample, out_sample, walk_timestep, epochs, batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "in_ap_scores = []\n",
    "in_prec_scores = []\n",
    "\n",
    "out_ap_scores = []\n",
    "out_prec_scores = []\n",
    "\n",
    "for in_pair in in_metrics_list:\n",
    "    in_ap_scores.append(in_pair[0])\n",
    "    in_prec_scores.append(in_pair[1])\n",
    "\n",
    "for out_pair in out_metrics_list:\n",
    "    out_ap_scores.append(out_pair[0])\n",
    "    out_prec_scores.append(out_pair[1])\n",
    "\n",
    "print(average(in_ap_scores))\n",
    "print(average(in_prec_scores))\n",
    "print(average(out_ap_scores))\n",
    "print(average(out_prec_scores))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}